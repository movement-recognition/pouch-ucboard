import time
import requests
import click
import pandas as pd
import numpy as np
from datetime import datetime

@click.group()
def cli():
    pass

@cli.command()
@click.option("--inputFile", default="data/rawData.csv", help="CSV-File generated by schnieboard to read the raw data from")
def list_markers(inputfile):
    with open(inputfile, "r") as f:
        raw_rows = []
        marker_rows = []
        for row in f.readlines():
            if ">;" not in row and "#;" not in row:
                print(row.strip())


@cli.command()
@click.option("--inputFile", help="CSV-File generated by schnieboard to read the raw data from")
@click.option("--startMarkerName", help="start marker name")
@click.option("--endMarkerName", help="end marker name")
@click.option("--startMarkerTime", help="YYYY-DD-MMTHH:MM:SS.ms (ISO-Time) where start marker is aligned to.")
@click.option("--influxBaseUrl", default="https://sensor:wd40@smartpouch.foobar.rocks/influx", help="URL to influx-server endpoint")
@click.option("--influxDatabase", default="master", help="Database-name of influx-server to write in")
@click.option("--influxTableName", default="schnieboard_meas", help="table name inside the influx-database, e.g. for debugging")
@click.option("--influxUploadBatchSize", default=100, help="batch size for uploads (# of rows in one request)")
@click.pass_context
def upload(ctx, inputfile, startmarkername, endmarkername, startmarkertime, influxbaseurl, influxdatabase, influxtablename, influxuploadbatchsize):

    date_format = "%Y-%m-%dT%H:%M:%S.%f"
    dt_object = datetime.strptime(startmarkertime, date_format)
    startmarkertime_timestamp = dt_object.timestamp()

    read_filename = inputfile
    mode = -1
    with open(read_filename, "r") as f:
        raw_rows = []
        for row in f.readlines():
            if ";meas;" in row and mode == -1:
                raw_rows.append(row.strip().split(";")) # get first row!
                mode = 0
            elif ";meas;" in row and mode == 1:
                raw_rows.append(row.strip().split(";"))
            elif ">;" not in row:
                if row.strip() == startmarkername:
                    print("start marker found!")
                    mode = 1
                elif row.strip() == endmarkername:
                    mode = 2
                    print("end marker found!")
    if mode == 0:
        print("WARNING: no start marker was found. aborting.")
        return
    elif mode == 1:
        print("WARNING: no end marker was found. using data from start marker to EOF.")
    else:
        print(f"{len(raw_rows)} rows between the markers found. now uploading.")

    df = pd.DataFrame(raw_rows[1:])
    df = df.rename(columns=dict(zip(df.columns, raw_rows[0])))
    grafana_string = ""
    batch_limit = influxuploadbatchsize
    batchct = 0
    for index, row in df.iterrows():
        substr = ""
        for k in row.keys():
            if k not in ["#", "meas", "ticks", 18]:
                substr += f"{k}={row[k]},"
        try:
            time_str = startmarkertime_timestamp * 1e6 + int(row["ticks"]) * 1000
        except:
            print("err", row)
        batchct += 1

        grafana_string += f"{influxtablename},sensor=pouch01,type=meas {substr.strip(',')} {round(time_str)}\n"
        if batchct >= batch_limit:
            r = requests.post(f"{influxbaseurl}/write?db={influxdatabase}&precision=u", grafana_string, timeout=10)
            if r.status_code >= 200 and r.status_code <= 299:
                print(f"\ruploading rows {index} / {df.shape[0]}", end="")
                grafana_string = ""
                batchct = 0
            else:
                print("req fail", r, r.text)

    print("\rUpload complete!")

if __name__ == "__main__":
    cli()
