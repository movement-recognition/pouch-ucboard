{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334593a2-a0e5-4a1d-b5ef-4ad5b7f46f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TENSORFLOW BEGIN\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fe8ace-2788-4533-968c-058ab8cc722a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"big_framedata.pkl\")\n",
    "\n",
    "data['label'] = pd.factorize(data['label'])[0] + 1\n",
    "features = data.drop('label', axis=1)\n",
    "labels = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73f73b9-7e72-4057-84d8-d5413cae4809",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_tensor = tf.convert_to_tensor(features.values, dtype=tf.float32)\n",
    "labels_tensor = tf.convert_to_tensor(labels.values, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1deac9-d1cb-4155-ba59-5a65a26a201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((features_tensor, labels_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcf8121-0640-4906-95cf-336e41b89c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_size, num_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Input(shape=(input_size,)),  # Replace 'input_shape' with the shape of your input data\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(num_classes)  # Replace 'num_classes' with the number of output classes\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25549d1-6832-46fd-9915-47c05d5b2192",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(30, 5)\n",
    "\n",
    "\n",
    "# Step 2: Specify the loss function and optimizer\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Step 3: Create the training loop\n",
    "batch_size = 32\n",
    "dataset = dataset.batch(batch_size)\n",
    "\n",
    "epochs = 5 # You can adjust the number of epochs based on your training needs\n",
    "losses = []\n",
    "# Iterate over epochs\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    \n",
    "    # Initialize the average loss metric\n",
    "    avg_loss = tf.keras.metrics.Mean()\n",
    "    \n",
    "    # Iterate over batches\n",
    "    for batch_features, batch_labels in dataset:\n",
    "        # Open a GradientTape to record the operations for automatic differentiation\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Perform forward pass\n",
    "            predictions = model(batch_features, training=True)\n",
    "            # Calculate the loss\n",
    "            loss = loss_object(batch_labels, predictions)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        # Apply gradients to update the model parameters\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        \n",
    "        # Update the average loss metric\n",
    "        avg_loss.update_state(loss)\n",
    "    \n",
    "    # Print the average loss for the epoch\n",
    "    print(f\"Average Loss: {avg_loss.result().numpy()}\")\n",
    "    losses.append(avg_loss.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9378dd-8002-4eb0-8529-8915458f473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model, \"2023-07-16_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ec608b-f398-4870-a7a4-69d38902989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_activations=True, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cb8112-b0fd-48c0-bcdf-df80248f335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.predict()\n",
    "row = big_frame.iloc[1009][1:]\n",
    "list(row)\n",
    "tf_row = tf.convert_to_tensor(row, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b995069b-457b-426b-91d2-6d9bb73be0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dir(model))\n",
    "model.weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
